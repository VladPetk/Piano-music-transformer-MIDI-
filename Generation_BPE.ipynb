{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daac23fe-29a1-4974-9192-cffa4217d668",
   "metadata": {},
   "source": [
    "# Genearting Continuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae01701-319e-4c86-964b-d34a4b4f2331",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0599d9-c0bd-4efc-a99e-72a828c81f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import miditok\n",
    "from music21 import converter, meter, stream, key\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler # Mixed Precision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from x_transformer2 import TransformerWrapper, Decoder, AutoregressiveWrapper\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3aae19-0f77-4be1-8b22-ff340c4eff65",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ea27b0-e1d1-4b7e-b86d-f99f40663e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = 1024\n",
    "depth_model = 32\n",
    "max_sequence = 1024\n",
    "\n",
    "model = TransformerWrapper(\n",
    "    num_tokens = 2002,\n",
    "    max_seq_len = max_sequence,\n",
    "    attn_layers = Decoder(dim = dim_model, depth = depth_model, heads = 16)\n",
    ")\n",
    "\n",
    "model = AutoregressiveWrapper(model)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182cd752-b78a-4855-8595-0ab02e638d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"ckpt/good_bpe/latest_bpe.pth\", map_location='cpu')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "#optim.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44368753-5380-4aba-9f66-9123649b4ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoregressiveWrapper(\n",
       "    (net): TransformerWrapper(\n",
       "      (token_emb): TokenEmbedding(\n",
       "        (emb): Embedding(2002, 1024)\n",
       "      )\n",
       "      (pos_emb): AbsolutePositionalEmbedding(\n",
       "        (emb): Embedding(1024, 1024)\n",
       "      )\n",
       "      (post_emb_norm): Identity()\n",
       "      (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (project_emb): Identity()\n",
       "      (attn_layers): Decoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (4): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (5): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (6): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (7): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (8): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (9): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (10): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (11): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (12): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (13): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (14): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (15): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (16): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (17): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (18): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (19): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (20): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (21): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (22): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (23): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (24): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (25): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (26): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (27): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (28): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (29): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (30): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (31): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (32): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (33): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (34): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (35): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (36): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (37): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (38): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (39): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (40): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (41): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (42): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (43): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (44): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (45): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (46): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (47): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (48): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (49): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (50): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (51): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (52): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (53): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (54): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (55): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (56): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (57): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (58): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (59): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (60): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (61): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (62): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (63): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_logits): Linear(in_features=1024, out_features=2002, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb131fac-9fe9-433e-ac6c-b520c359642d",
   "metadata": {},
   "source": [
    "### Setup the MIDI tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6ab92c-71d1-4e9b-9bcc-280fb40ef458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our parameters\n",
    "CHORD_MAPS = {\n",
    "    \"min\": (0, 3, 7),\n",
    "    \"maj\": (0, 4, 7),\n",
    "    \"dim\": (0, 3, 6),\n",
    "    \"aug\": (0, 4, 8),\n",
    "    \"sus2\": (0, 2, 7),\n",
    "    \"sus4\": (0, 5, 7),\n",
    "    \"7dom\": (0, 4, 7, 10),\n",
    "    \"7min\": (0, 3, 7, 10),\n",
    "    \"7maj\": (0, 4, 7, 11),\n",
    "    \"7halfdim\": (0, 3, 6, 10),\n",
    "    \"7dim\": (0, 3, 6, 9),\n",
    "    \"7aug\": (0, 4, 8, 11),\n",
    "    \"9maj\": (0, 4, 7, 10, 14),\n",
    "    \"9min\": (0, 4, 7, 10, 13),\n",
    "}\n",
    "\n",
    "TS_MAPS = {16: [15, 11, 7, 4, 3, 12, 6], 8: [3, 12, 6, 7, 5, 9], 4: [5, 6, 3, 2, 1, 4, 9], 2: [3, 2, 4, 1]}\n",
    "\n",
    "\n",
    "TOKENIZER_PARAMS2 = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 4): 8, (4, 12): 4},\n",
    "    \"nb_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"EOS\"],\n",
    "    \"use_chords\": True,\n",
    "    \"chord_maps\": CHORD_MAPS,\n",
    "    \"use_rests\": True,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": True,\n",
    "    \"time_signature_range\": TS_MAPS,\n",
    "    \"use_programs\": False,\n",
    "    \"use_sustain_pedals\": False,\n",
    "    \"nb_tempos\": 32,  # nb of tempo bins\n",
    "    \"tempo_range\": (40, 250),  # (min, max)\n",
    "}\n",
    "config = miditok.TokenizerConfig(**TOKENIZER_PARAMS2)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = miditok.REMI(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd7d0a5-75c6-40d5-90ef-33d45a190c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved tokenizer (for BPE)\n",
    "tokenizer = pickle.load(open('tokenizer_bpe.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc3bf8-bf72-48fb-8537-b9f50aa2a461",
   "metadata": {},
   "source": [
    "## From raw MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6db882-4d4f-4f95-81c3-7b7016317e72",
   "metadata": {},
   "source": [
    "### Load the samples and transpose them to C major/ A minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "405887ce-4804-4a6a-abdc-f9fca18ba9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('test_toks'):\n",
    "    test_ts += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bee60b5-6427-4dea-9e9f-e1562f40e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_midi(midi_file_path, out_dir):\n",
    "\n",
    "    try:     \n",
    "        # Load MIDI file\n",
    "        midi_stream = converter.parse(midi_file_path)\n",
    "    \n",
    "        # Analyze key signature of the original MIDI file\n",
    "        original_key = midi_stream.analyze('key')\n",
    "        \n",
    "        original_mode = original_key.mode  # Get the mode of the original key\n",
    "    \n",
    "        # Set the target key based on the mode of the original key\n",
    "        if original_mode == 'major':\n",
    "            new_key = key.Key('C')\n",
    "        elif original_mode == 'minor':\n",
    "            new_key = key.Key('a')\n",
    "    \n",
    "        # Calculate the interval to transpose\n",
    "        interval = key.interval.Interval(original_key.tonic, new_key.tonic)\n",
    "    \n",
    "        # Transpose the entire stream\n",
    "        transposed_stream = midi_stream.transpose(interval)\n",
    "\n",
    "        if out_dir is not None:\n",
    "            base_midi = os.path.basename(midi_file_path)\n",
    "            output_path = os.path.join(out_dir, base_midi)\n",
    "    \n",
    "            transposed_stream.write('midi', fp=output_path)\n",
    "        else:\n",
    "            return transposed_stream\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962ed310-80bc-4040-bac9-35163e0ea122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [00:16<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "for midi_path in tqdm.tqdm(test_ts):\n",
    "    transpose_midi(midi_path, 'test_toks_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de695ef2-7f50-4e07-83c0-0a00451fdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts_norm = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('test_toks_norm'):\n",
    "    test_ts_norm += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d74aae5a-7355-4ebe-88ce-a31a2d7a071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = tokenizer(test_ts_norm[0])\n",
    "tokenizer.apply_bpe(midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8725d1-75fa-4955-9315-fb8b15df80c9",
   "metadata": {},
   "source": [
    "### Generate many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c4e6b61-a1fa-4aac-8354-84d4aa7c427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [12:59<00:00, 59.95s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "for f in tqdm.tqdm(test_ts_norm):\n",
    "    midi = tokenizer(f)\n",
    "    tokenizer.apply_bpe(midi)\n",
    "    name = os.path.basename(f)\n",
    "    name = name[:-4]\n",
    "    tokens = ([x for x in midi[0]])\n",
    "    batch = [tokens]*batch_size\n",
    "    tokens = torch.LongTensor(batch).cuda()\n",
    "    with autocast():\n",
    "        sample = model.module.generate(tokens, 512, temperature=1, return_prime=False, verbose=False)\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        out = sample[i].tolist()\n",
    "        out = [x for x in out if x != 2001]\n",
    "        out_midi = tokenizer.tokens_to_midi([out])\n",
    "        out_midi.dump(f'generated_bpe/gen_{name}_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ec09e-a9fe-456a-aab0-cf732f92f255",
   "metadata": {},
   "source": [
    "### Generate from signle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_midi('Piano.mid', 'test_toks_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e0f1c2-85d5-4536-8e59-3901592f8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = tokenizer('test_toks_norm/Piano.mid')\n",
    "tokenizer.apply_bpe(midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1456685-bee6-4905-bb5b-d727e4825d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequence of max length: 512\n",
      "0 / 512\n",
      "32 / 512\n",
      "64 / 512\n",
      "96 / 512\n",
      "128 / 512\n",
      "160 / 512\n",
      "192 / 512\n",
      "224 / 512\n",
      "256 / 512\n",
      "288 / 512\n",
      "320 / 512\n",
      "352 / 512\n",
      "384 / 512\n",
      "416 / 512\n",
      "448 / 512\n",
      "480 / 512\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "tokens = ([x for x in midi[0]])\n",
    "batch = [tokens]*batch_size\n",
    "tokens = torch.LongTensor(batch).cuda()\n",
    "with autocast():\n",
    "    sample = model.module.generate(tokens, 512, temperature=1, return_prime=False, verbose=True)\n",
    "\n",
    "for i in range(0, batch_size):\n",
    "    out = sample[i].tolist()\n",
    "    out = [x for x in out if x != 2001]\n",
    "    out_midi = tokenizer.tokens_to_midi([out])\n",
    "    out_midi.dump(f'generated_custom/gen_Piano_mine_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3e717-ff2c-4f77-b0ce-ed6cd61e921b",
   "metadata": {},
   "source": [
    "## Generate from tokenized data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d4855-382b-4c14-9330-9b31e966e267",
   "metadata": {},
   "source": [
    "### Load tokenized sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10bb83d0-c265-4122-a30b-623966cf0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('data_remi_norm_bpe/test'):\n",
    "    test_fs += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f5d75-ed7c-4ca6-9bdd-88cae5a384f9",
   "metadata": {},
   "source": [
    "### Single file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110607ba-e7f8-4085-92e6-de2c41e1d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = [json.load(open(test_fs[2]))['ids'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af66c7e-5833-4e7b-9ca8-1933fd2198b2",
   "metadata": {},
   "source": [
    "#### Load into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32905a05-2885-4f13-9525-6a29a9d58b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c0c074-1ca5-4001-a368-4bfd5ab2a943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = ([x for x in midi[0]])\n",
    "batch = [tokens]*batch_size\n",
    "tokens = torch.LongTensor(batch).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c60c0515-2a7f-4441-b1d9-5822ab9e5afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequence of max length: 512\n",
      "0 / 512\n",
      "32 / 512\n",
      "64 / 512\n",
      "96 / 512\n",
      "128 / 512\n",
      "160 / 512\n",
      "192 / 512\n",
      "224 / 512\n",
      "256 / 512\n",
      "288 / 512\n",
      "320 / 512\n",
      "352 / 512\n",
      "384 / 512\n",
      "416 / 512\n",
      "448 / 512\n",
      "480 / 512\n"
     ]
    }
   ],
   "source": [
    "with autocast():\n",
    "    sample = model.module.generate(tokens, 512, temperature=1, return_prime=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383f498-86dc-4706-b6a7-fda7cbd89c02",
   "metadata": {},
   "source": [
    "#### Generate in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "803a0770-dfc2-43a0-b1ab-91d4d5347396",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_list = list()\n",
    "for i in range(0, batch_size):\n",
    "    out = sample[i].tolist()\n",
    "    out = [x for x in out if x != 2001]\n",
    "    out_midi = tokenizer.tokens_to_midi([out])\n",
    "    out_midi.dump(f'generated_bpe/generated_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b110c8-e655-49e0-9b8b-a0352cdc5e65",
   "metadata": {},
   "source": [
    "### Generate from many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99913080-e8de-4aa3-b18f-b8208172c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [10:04<00:00, 60.41s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "for f in tqdm.tqdm(test_fs[0:10]):\n",
    "    midi = [json.load(open(f))['ids'][0]]\n",
    "    name = os.path.basename(f)\n",
    "    name = name[:-5]\n",
    "    tokens = ([x for x in midi[0]])\n",
    "    batch = [tokens]*batch_size\n",
    "    tokens = torch.LongTensor(batch).cuda()\n",
    "    with autocast():\n",
    "        sample = model.module.generate(tokens, 512, temperature=1, return_prime=False, verbose=False)\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        out = sample[i].tolist()\n",
    "        out = [x for x in out if x != 2001]\n",
    "        out_midi = tokenizer.tokens_to_midi([out])\n",
    "        out_midi.dump(f'generated_bpe/gen_{name}_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250fc07-51a6-4854-80cc-7617dd288f25",
   "metadata": {},
   "source": [
    "## Zip all generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "764dde8a-f256-461b-9ed5-48ecace970ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "def zip_folder(folder_path, zip_path):\n",
    "    with ZipFile(zip_path, 'w') as zip_file:\n",
    "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(foldername, filename)\n",
    "                arcname = os.path.relpath(file_path, folder_path)\n",
    "                zip_file.write(file_path, arcname)\n",
    "\n",
    "# Example usage:\n",
    "folder_to_zip = 'generated'\n",
    "zip_file_path = 'gens.zip'\n",
    "\n",
    "zip_folder(folder_to_zip, zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9edbf181-e9af-4142-8479-c9d565a390ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sample in a zip\n",
    "import random\n",
    "\n",
    "def zip_random_files(folder_path, zip_path, sample_size):\n",
    "    all_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
    "    \n",
    "    # Ensure the sample size is not greater than the number of files in the folder\n",
    "    sample_size = min(sample_size, len(all_files))\n",
    "\n",
    "    # Randomly select files for the sample\n",
    "    selected_files = random.sample(all_files, sample_size)\n",
    "\n",
    "    with ZipFile(zip_path, 'w') as zip_file:\n",
    "        for file_path in selected_files:\n",
    "            arcname = os.path.relpath(file_path, folder_path)\n",
    "            zip_file.write(file_path, arcname)\n",
    "\n",
    "# Example usage:\n",
    "folder_to_sample = 'norm_midi'\n",
    "zip_file_path = 'midi_sample.zip'\n",
    "sample_size = 100  # Adjust this to the desired sample size\n",
    "\n",
    "zip_random_files(folder_to_sample, zip_file_path, sample_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
