{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daac23fe-29a1-4974-9192-cffa4217d668",
   "metadata": {},
   "source": [
    "# Genearting Continuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae01701-319e-4c86-964b-d34a4b4f2331",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0599d9-c0bd-4efc-a99e-72a828c81f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import miditok\n",
    "from music21 import converter, meter, stream, key\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler # Mixed Precision\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from x_transformer2 import TransformerWrapper, Decoder, AutoregressiveWrapper\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3aae19-0f77-4be1-8b22-ff340c4eff65",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ea27b0-e1d1-4b7e-b86d-f99f40663e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_model = 1024\n",
    "depth_model = 32\n",
    "max_sequence = 1024\n",
    "\n",
    "model = TransformerWrapper(\n",
    "    num_tokens = 2002,\n",
    "    max_seq_len = max_sequence,\n",
    "    attn_layers = Decoder(dim = dim_model, depth = depth_model, heads = 16)\n",
    ")\n",
    "\n",
    "model = AutoregressiveWrapper(model)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182cd752-b78a-4855-8595-0ab02e638d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"ckpt/good_bpe/latest_bpe.pth\", map_location='cpu')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "#optim.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44368753-5380-4aba-9f66-9123649b4ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AutoregressiveWrapper(\n",
       "    (net): TransformerWrapper(\n",
       "      (token_emb): TokenEmbedding(\n",
       "        (emb): Embedding(2002, 1024)\n",
       "      )\n",
       "      (pos_emb): AbsolutePositionalEmbedding(\n",
       "        (emb): Embedding(1024, 1024)\n",
       "      )\n",
       "      (post_emb_norm): Identity()\n",
       "      (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "      (project_emb): Identity()\n",
       "      (attn_layers): Decoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (3): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (4): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (5): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (6): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (7): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (8): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (9): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (10): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (11): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (12): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (13): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (14): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (15): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (16): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (17): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (18): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (19): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (20): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (21): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (22): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (23): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (24): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (25): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (26): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (27): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (28): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (29): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (30): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (31): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (32): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (33): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (34): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (35): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (36): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (37): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (38): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (39): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (40): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (41): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (42): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (43): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (44): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (45): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (46): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (47): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (48): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (49): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (50): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (51): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (52): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (53): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (54): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (55): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (56): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (57): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (58): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (59): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (60): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (61): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (62): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): Attention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (attend): Attend(\n",
       "                (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (to_out): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "          (63): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (1-2): 2 x None\n",
       "            )\n",
       "            (1): FeedForward(\n",
       "              (ff): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                )\n",
       "                (1): Identity()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Residual()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (to_logits): Linear(in_features=1024, out_features=2002, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb131fac-9fe9-433e-ac6c-b520c359642d",
   "metadata": {},
   "source": [
    "### Setup the MIDI tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6ab92c-71d1-4e9b-9bcc-280fb40ef458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our parameters\n",
    "CHORD_MAPS = {\n",
    "    \"min\": (0, 3, 7),\n",
    "    \"maj\": (0, 4, 7),\n",
    "    \"dim\": (0, 3, 6),\n",
    "    \"aug\": (0, 4, 8),\n",
    "    \"sus2\": (0, 2, 7),\n",
    "    \"sus4\": (0, 5, 7),\n",
    "    \"7dom\": (0, 4, 7, 10),\n",
    "    \"7min\": (0, 3, 7, 10),\n",
    "    \"7maj\": (0, 4, 7, 11),\n",
    "    \"7halfdim\": (0, 3, 6, 10),\n",
    "    \"7dim\": (0, 3, 6, 9),\n",
    "    \"7aug\": (0, 4, 8, 11),\n",
    "    \"9maj\": (0, 4, 7, 10, 14),\n",
    "    \"9min\": (0, 4, 7, 10, 13),\n",
    "}\n",
    "\n",
    "TS_MAPS = {16: [15, 11, 7, 4, 3, 12, 6], 8: [3, 12, 6, 7, 5, 9], 4: [5, 6, 3, 2, 1, 4, 9], 2: [3, 2, 4, 1]}\n",
    "\n",
    "\n",
    "TOKENIZER_PARAMS2 = {\n",
    "    \"pitch_range\": (21, 109),\n",
    "    \"beat_res\": {(0, 4): 8, (4, 12): 4},\n",
    "    \"nb_velocities\": 32,\n",
    "    \"special_tokens\": [\"PAD\", \"EOS\"],\n",
    "    \"use_chords\": True,\n",
    "    \"chord_maps\": CHORD_MAPS,\n",
    "    \"use_rests\": True,\n",
    "    \"use_tempos\": True,\n",
    "    \"use_time_signatures\": True,\n",
    "    \"time_signature_range\": TS_MAPS,\n",
    "    \"use_programs\": False,\n",
    "    \"use_sustain_pedals\": False,\n",
    "    \"nb_tempos\": 32,  # nb of tempo bins\n",
    "    \"tempo_range\": (40, 250),  # (min, max)\n",
    "}\n",
    "config = miditok.TokenizerConfig(**TOKENIZER_PARAMS2)\n",
    "\n",
    "# Creates the tokenizer\n",
    "tokenizer = miditok.REMI(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd7d0a5-75c6-40d5-90ef-33d45a190c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open('tokenizer_bpe.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0683d0-08b3-4181-b721-1bd5cd4a2327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab_bpe.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc3bf8-bf72-48fb-8537-b9f50aa2a461",
   "metadata": {},
   "source": [
    "## From raw MIDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6db882-4d4f-4f95-81c3-7b7016317e72",
   "metadata": {},
   "source": [
    "### Load the samples and transpose them to C major/ A minor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "405887ce-4804-4a6a-abdc-f9fca18ba9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('test_toks'):\n",
    "    test_ts += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bee60b5-6427-4dea-9e9f-e1562f40e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_midi(midi_file_path, out_dir):\n",
    "\n",
    "    try:     \n",
    "        # Load MIDI file\n",
    "        midi_stream = converter.parse(midi_file_path)\n",
    "    \n",
    "        # Analyze key signature of the original MIDI file\n",
    "        original_key = midi_stream.analyze('key')\n",
    "        \n",
    "        original_mode = original_key.mode  # Get the mode of the original key\n",
    "    \n",
    "        # Set the target key based on the mode of the original key\n",
    "        if original_mode == 'major':\n",
    "            new_key = key.Key('C')\n",
    "        elif original_mode == 'minor':\n",
    "            new_key = key.Key('a')\n",
    "    \n",
    "        # Calculate the interval to transpose\n",
    "        interval = key.interval.Interval(original_key.tonic, new_key.tonic)\n",
    "    \n",
    "        # Transpose the entire stream\n",
    "        transposed_stream = midi_stream.transpose(interval)\n",
    "\n",
    "        if out_dir is not None:\n",
    "            base_midi = os.path.basename(midi_file_path)\n",
    "            output_path = os.path.join(out_dir, base_midi)\n",
    "    \n",
    "            transposed_stream.write('midi', fp=output_path)\n",
    "        else:\n",
    "            return transposed_stream\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "962ed310-80bc-4040-bac9-35163e0ea122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [00:16<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "for midi_path in tqdm.tqdm(test_ts):\n",
    "    transpose_midi(midi_path, 'test_toks_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de695ef2-7f50-4e07-83c0-0a00451fdef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ts_norm = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('test_toks_norm'):\n",
    "    test_ts_norm += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef9f877-15b0-4fb1-af50-fbda12af7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_midi('Piano.mid', 'test_toks_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d74aae5a-7355-4ebe-88ce-a31a2d7a071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = tokenizer(test_ts_norm[0])\n",
    "tokenizer.apply_bpe(midi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8725d1-75fa-4955-9315-fb8b15df80c9",
   "metadata": {},
   "source": [
    "### Generate many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c4e6b61-a1fa-4aac-8354-84d4aa7c427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [12:59<00:00, 59.95s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "for f in tqdm.tqdm(test_ts_norm):\n",
    "    midi = tokenizer(f)\n",
    "    tokenizer.apply_bpe(midi)\n",
    "    name = os.path.basename(f)\n",
    "    name = name[:-4]\n",
    "    tokens = ([x for x in midi[0]])\n",
    "    batch = [tokens]*batch_size\n",
    "    tokens = torch.LongTensor(batch).cuda()\n",
    "    with autocast():\n",
    "        sample = model.module.generate(tokens, 512, temperature=1, return_prime=False, verbose=False)\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        out = sample[i].tolist()\n",
    "        out = [x for x in out if x != 2001]\n",
    "        out_midi = tokenizer.tokens_to_midi([out])\n",
    "        out_midi.dump(f'generated_bpe/gen_{name}_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ec09e-a9fe-456a-aab0-cf732f92f255",
   "metadata": {},
   "source": [
    "### Generate from signle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e0f1c2-85d5-4536-8e59-3901592f8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = tokenizer('test_toks_norm/Piano.mid')\n",
    "tokenizer.apply_bpe(midi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1456685-bee6-4905-bb5b-d727e4825d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequence of max length: 512\n",
      "0 / 512\n",
      "32 / 512\n",
      "64 / 512\n",
      "96 / 512\n",
      "128 / 512\n",
      "160 / 512\n",
      "192 / 512\n",
      "224 / 512\n",
      "256 / 512\n",
      "288 / 512\n",
      "320 / 512\n",
      "352 / 512\n",
      "384 / 512\n",
      "416 / 512\n",
      "448 / 512\n",
      "480 / 512\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "tokens = ([x for x in midi[0]])\n",
    "batch = [tokens]*batch_size\n",
    "tokens = torch.LongTensor(batch).cuda()\n",
    "with autocast():\n",
    "    sample = model.module.generate(tokens, 512, temperature=1, return_prime=False, verbose=True)\n",
    "\n",
    "for i in range(0, batch_size):\n",
    "    out = sample[i].tolist()\n",
    "    out = [x for x in out if x != 2001]\n",
    "    out_midi = tokenizer.tokens_to_midi([out])\n",
    "    out_midi.dump(f'generated_custom/gen_Piano_mine_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3e717-ff2c-4f77-b0ce-ed6cd61e921b",
   "metadata": {},
   "source": [
    "## Generate from tokenized data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064d4855-382b-4c14-9330-9b31e966e267",
   "metadata": {},
   "source": [
    "### Load tokenized sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10bb83d0-c265-4122-a30b-623966cf0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fs = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('data_remi_norm_bpe/test'):\n",
    "    test_fs += [os.path.join(dirpath, file) for file in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "078e1e65-f731-4092-802b-89618ba732de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_remi_norm_bpe/test/37fce7d256928de37af07d4785e308c2.json',\n",
       " 'data_remi_norm_bpe/test/7a93a72818c38cdd83c7450a1a7763ff.json',\n",
       " 'data_remi_norm_bpe/test/prelud24.json',\n",
       " 'data_remi_norm_bpe/test/2f09ede0d2c1612152a5d4b7b1d056a2.json',\n",
       " 'data_remi_norm_bpe/test/fe4125ffccdd6867e388836babcb9249.json',\n",
       " 'data_remi_norm_bpe/test/7a8773bf7d216941dbdb72cc5b1953b6.json',\n",
       " 'data_remi_norm_bpe/test/183f1b1d489c3bf1d9bed6e6877d88d6.json',\n",
       " 'data_remi_norm_bpe/test/c566cd86984aa1eac375fa81d4e459c8.json',\n",
       " 'data_remi_norm_bpe/test/fae0dce714f5999aaf70a235afac0299.json',\n",
       " 'data_remi_norm_bpe/test/d42551845593660dec5cca0a51956303.json',\n",
       " 'data_remi_norm_bpe/test/c4c7ed439995078374ac1f4a8bab85c6.json',\n",
       " 'data_remi_norm_bpe/test/f61c5f0747f572202f53e52a343db6f4.json',\n",
       " 'data_remi_norm_bpe/test/aca9c4afb4cca503dfec7bdee13f4b04.json',\n",
       " 'data_remi_norm_bpe/test/898fe13aee487da2b9d9f648142e23cf.json',\n",
       " 'data_remi_norm_bpe/test/14a94427536d12a213c2115f1620a8fb.json',\n",
       " 'data_remi_norm_bpe/test/48cc235c394013c98a6e5163beaab273.json',\n",
       " 'data_remi_norm_bpe/test/2c05a93d6568c15a2635d196685b8458.json',\n",
       " 'data_remi_norm_bpe/test/Harpsichord Suite in G Hwv432 1mov.json',\n",
       " 'data_remi_norm_bpe/test/dc39b4ee9d2a84c634029805865a3447.json',\n",
       " 'data_remi_norm_bpe/test/faed94c8c401e2ba14ce2d45cd26c430.json',\n",
       " 'data_remi_norm_bpe/test/7985e73f89b3b264fcd5f9ee8bec4b17.json',\n",
       " 'data_remi_norm_bpe/test/d9167c65f7808474e0c271457fe32650.json',\n",
       " 'data_remi_norm_bpe/test/d1a763f35329d13f2a31435c96933e6a.json',\n",
       " 'data_remi_norm_bpe/test/13f79fcf1b95d3e39fef7f61eb52c2ac.json',\n",
       " 'data_remi_norm_bpe/test/6731ce80f6edc9be425a9c442abb5b53.json',\n",
       " 'data_remi_norm_bpe/test/6bb053bdc8612636098a2f98d43592c5.json',\n",
       " 'data_remi_norm_bpe/test/3ef6d12bd229bcffba57e188b354a81b.json',\n",
       " 'data_remi_norm_bpe/test/230ed1306670d1dda7a9ed7fb06190d7.json',\n",
       " 'data_remi_norm_bpe/test/bd1af2e98974fbc5b47430de7c1a6b0d.json',\n",
       " 'data_remi_norm_bpe/test/4cb8a62d559977523892e502ca8ff2ff.json',\n",
       " 'data_remi_norm_bpe/test/5f97f0b54d2fcfef6c52be8244cdf074.json',\n",
       " 'data_remi_norm_bpe/test/eb16f20df2025f767cd181e48b2c6e63.json',\n",
       " 'data_remi_norm_bpe/test/6cdfc56f9d2d3784af7159ba43888f90.json',\n",
       " 'data_remi_norm_bpe/test/7358d80f9eaff2aee866944fc02f18f4.json',\n",
       " 'data_remi_norm_bpe/test/73543b47ac8af127ccd81d2790c66317.json',\n",
       " 'data_remi_norm_bpe/test/2222ee5c5012c807f05ed3527d5ea8b6.json',\n",
       " 'data_remi_norm_bpe/test/c3c77f6d9e28bd4aaca3bc20c23f8c22.json',\n",
       " 'data_remi_norm_bpe/test/3a54c5e563fdd2ea46bad234080ef8aa.json',\n",
       " 'data_remi_norm_bpe/test/c032f08e0d288331e14e6a9ef7bbcb2d.json',\n",
       " 'data_remi_norm_bpe/test/213be1d2b1bd26c9d21a25e1813c56dd.json',\n",
       " 'data_remi_norm_bpe/test/48c2d467456210c00adda24ace725aac.json',\n",
       " 'data_remi_norm_bpe/test/bb40d3d44c72dcdb379c60b625deaa12.json',\n",
       " 'data_remi_norm_bpe/test/6a71336ed084bf361fe4049d8de58a2c.json',\n",
       " 'data_remi_norm_bpe/test/90a8bb992538461498efda26439e8cde.json',\n",
       " 'data_remi_norm_bpe/test/ab61f9eee1be1962c4f8c9baf9056df1.json',\n",
       " 'data_remi_norm_bpe/test/e25ccbe94813136d423e15fdabe1b48f.json',\n",
       " 'data_remi_norm_bpe/test/fd498b9721b7e00af3f5126ecfda4e47.json',\n",
       " 'data_remi_norm_bpe/test/e10f89ae31bb8ffc75baf6903f775056.json',\n",
       " 'data_remi_norm_bpe/test/173d0d8061b108be8c23df15501d600d.json',\n",
       " 'data_remi_norm_bpe/test/bd93e6b261001cd6780d29005ba24c31.json',\n",
       " 'data_remi_norm_bpe/test/83cbd29bb097f8b13b1c5c55d30ba5ed.json',\n",
       " 'data_remi_norm_bpe/test/9ea6a818bc7f5d2256228943c6cee788.json',\n",
       " 'data_remi_norm_bpe/test/760d4518ac0e8217b7b6438a09587825.json',\n",
       " 'data_remi_norm_bpe/test/7daa0a14dfc32f0d82060dca6bac5b60.json',\n",
       " 'data_remi_norm_bpe/test/35aadd76fecaefe658c9718dafcf57c0.json',\n",
       " 'data_remi_norm_bpe/test/4480579d4a8951c68a8003e39ab3f4d5.json',\n",
       " 'data_remi_norm_bpe/test/728703e37fb72c280241b8f60ae6fd8f.json',\n",
       " 'data_remi_norm_bpe/test/29791dec1de7df8518347887621d009b.json',\n",
       " 'data_remi_norm_bpe/test/09349be6eb30bb68c2d9f07c445ac577.json',\n",
       " 'data_remi_norm_bpe/test/72d73f7fa1bc390c7138fc5619a09d38.json',\n",
       " 'data_remi_norm_bpe/test/4cab72083cd0ee25c687447da95d0036.json',\n",
       " 'data_remi_norm_bpe/test/026100b_.json',\n",
       " 'data_remi_norm_bpe/test/5426b7451ff1e9f9964b1e8ba33a2e83.json',\n",
       " 'data_remi_norm_bpe/test/the-star-spangled-banner.json',\n",
       " 'data_remi_norm_bpe/test/87c7a4ba9b67254aaee96686a3767e1f.json',\n",
       " 'data_remi_norm_bpe/test/d151016122b1ab9ee2d74e939f55411f.json',\n",
       " 'data_remi_norm_bpe/test/f47480b7489826ae582206f857ea4ad4.json',\n",
       " 'data_remi_norm_bpe/test/0ac15255e3dfa6edfdaf1b1f3bc5d83e.json',\n",
       " 'data_remi_norm_bpe/test/02c761162ad4e9b29919ec10bf319134.json',\n",
       " 'data_remi_norm_bpe/test/5ed814e69368056f47055a106d1a0b53.json',\n",
       " 'data_remi_norm_bpe/test/60d82f7759c9603f6a537a790cef6aeb.json',\n",
       " 'data_remi_norm_bpe/test/2a68fd5786e581b201bb0be62fbf8357.json',\n",
       " 'data_remi_norm_bpe/test/ave.json',\n",
       " 'data_remi_norm_bpe/test/885f61528e11fd5574b39219f71a7f43.json',\n",
       " 'data_remi_norm_bpe/test/ec3794df293f7b5c1e714304d9f89723.json',\n",
       " 'data_remi_norm_bpe/test/b418a78841c1708d24693a2dc050abf4.json',\n",
       " 'data_remi_norm_bpe/test/6303261a8138f4c6533dc93743b0ea4c.json',\n",
       " 'data_remi_norm_bpe/test/a86055b3af5553435d3a27309af1f238.json',\n",
       " 'data_remi_norm_bpe/test/4a9f202bb7d524369448c76f31242653.json',\n",
       " 'data_remi_norm_bpe/test/8e148568b575cb9d95483ec666e73e8f.json',\n",
       " 'data_remi_norm_bpe/test/2b059c119b4cb4201ae971270fa6bc92.json',\n",
       " 'data_remi_norm_bpe/test/3fe2d3c3680ec14d546737bc5a0b70c2.json',\n",
       " 'data_remi_norm_bpe/test/8f7d0b8b46631b6cb8b10f2b8c9238b7.json',\n",
       " 'data_remi_norm_bpe/test/978df14f3a30e07a0bee37a0e8a6ebad.json',\n",
       " 'data_remi_norm_bpe/test/Variation 18.json',\n",
       " 'data_remi_norm_bpe/test/3aa7fb6c622a5f1d4e0da83f6a8c3708.json',\n",
       " 'data_remi_norm_bpe/test/68efe488ccccc22178422f233b0c2444.json',\n",
       " 'data_remi_norm_bpe/test/13c14aad922ffa94d4b8bd425cbbb234.json',\n",
       " 'data_remi_norm_bpe/test/b7e3422bb5abb96df1c3f6a2882ab067.json',\n",
       " 'data_remi_norm_bpe/test/d75462a25318277737c42c835e800dd9.json',\n",
       " 'data_remi_norm_bpe/test/fa47cd897e20b41633a85ab71fef3d33.json',\n",
       " 'data_remi_norm_bpe/test/dca40ed14dab8eaa61ad9c879decf5b5.json',\n",
       " 'data_remi_norm_bpe/test/42e66370d9980942fe3fb95aa571744e.json',\n",
       " 'data_remi_norm_bpe/test/de873b5ca1c53f77927ca62eb606fe9c.json',\n",
       " 'data_remi_norm_bpe/test/edward-elgar-enigma-variations-nimrod-for-piano.json',\n",
       " 'data_remi_norm_bpe/test/burlesq1.json',\n",
       " 'data_remi_norm_bpe/test/cf1f04414359270b840eb92076b77fc3.json',\n",
       " 'data_remi_norm_bpe/test/6d44deebbf2cff88928309916becbd97.json',\n",
       " 'data_remi_norm_bpe/test/f22caa517e317b16a4361bad78e9d524.json',\n",
       " 'data_remi_norm_bpe/test/97343070d55b08057d0fcf5146a9769b.json',\n",
       " 'data_remi_norm_bpe/test/78b54d5f9a2abf1e79ef50060a9ac073.json',\n",
       " 'data_remi_norm_bpe/test/87d542666f2c1d80b1569c8486702f92.json',\n",
       " 'data_remi_norm_bpe/test/64776e32b81a6e42deb3bf821966b673.json',\n",
       " 'data_remi_norm_bpe/test/7e93440a5f94fc7ab5ee681dd727d9a2.json',\n",
       " 'data_remi_norm_bpe/test/09caacd3a3f1cf2fd606f01688d1f61b.json',\n",
       " 'data_remi_norm_bpe/test/30c1b50b1df626bc475263c66f71d7cb.json',\n",
       " 'data_remi_norm_bpe/test/eada568093591d37905dbf3ba526eb80.json',\n",
       " 'data_remi_norm_bpe/test/824022e639e7f1fa60768ef9e941c866.json',\n",
       " 'data_remi_norm_bpe/test/7e632b975c4db99118dc9b606c09d3c8.json',\n",
       " 'data_remi_norm_bpe/test/73ddeb35983a76bbb6dc796ee65c7361.json',\n",
       " 'data_remi_norm_bpe/test/6fa9ded1d2eb1dca3daf4606aad4d83b.json',\n",
       " 'data_remi_norm_bpe/test/d37495fb65297c96c302362e4a55f80b.json',\n",
       " 'data_remi_norm_bpe/test/eaafedd79e3c61ea857d277f45ef64c4.json',\n",
       " 'data_remi_norm_bpe/test/b5804b4a73ebcc85adda89a732671094.json',\n",
       " 'data_remi_norm_bpe/test/cca76b6da8d5d0ab94490997867aebd1.json',\n",
       " 'data_remi_norm_bpe/test/283c92d0c31d993c26a7c8ec4951e056.json',\n",
       " 'data_remi_norm_bpe/test/6e42aae035641314c0664b14e12c7a37.json']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110607ba-e7f8-4085-92e6-de2c41e1d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = [json.load(open(test_fs[2]))['ids'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f5d75-ed7c-4ca6-9bdd-88cae5a384f9",
   "metadata": {},
   "source": [
    "### Single file generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af66c7e-5833-4e7b-9ca8-1933fd2198b2",
   "metadata": {},
   "source": [
    "#### Load into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32905a05-2885-4f13-9525-6a29a9d58b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c0c074-1ca5-4001-a368-4bfd5ab2a943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = ([x for x in midi[0]])\n",
    "batch = [tokens]*batch_size\n",
    "tokens = torch.LongTensor(batch).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d6a093-cc51-4078-a8b0-312d721bf159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[370, 310,  27,  ..., 668,  51, 668],\n",
       "        [370, 310,  27,  ..., 668,  51, 668],\n",
       "        [370, 310,  27,  ..., 668,  51, 668],\n",
       "        ...,\n",
       "        [370, 310,  27,  ..., 668,  51, 668],\n",
       "        [370, 310,  27,  ..., 668,  51, 668],\n",
       "        [370, 310,  27,  ..., 668,  51, 668]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c60c0515-2a7f-4441-b1d9-5822ab9e5afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequence of max length: 512\n",
      "0 / 512\n",
      "32 / 512\n",
      "64 / 512\n",
      "96 / 512\n",
      "128 / 512\n",
      "160 / 512\n",
      "192 / 512\n",
      "224 / 512\n",
      "256 / 512\n",
      "288 / 512\n",
      "320 / 512\n",
      "352 / 512\n",
      "384 / 512\n",
      "416 / 512\n",
      "448 / 512\n",
      "480 / 512\n"
     ]
    }
   ],
   "source": [
    "with autocast():\n",
    "    sample = model.module.generate(tokens, 512, temperature=1, return_prime=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00063d7b-5a21-4613-b733-1a0f581744e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sample[0].tolist()\n",
    "out = \n",
    "out2 = tokenizer.decode_bpe(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383f498-86dc-4706-b6a7-fda7cbd89c02",
   "metadata": {},
   "source": [
    "#### Generate in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "803a0770-dfc2-43a0-b1ab-91d4d5347396",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_list = list()\n",
    "for i in range(0, batch_size):\n",
    "    out = sample[i].tolist()\n",
    "    out = [x for x in out if x != 2001]\n",
    "    out_midi = tokenizer.tokens_to_midi([out])\n",
    "    out_midi.dump(f'generated_bpe/generated_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b110c8-e655-49e0-9b8b-a0352cdc5e65",
   "metadata": {},
   "source": [
    "### Generate from many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99913080-e8de-4aa3-b18f-b8208172c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [10:04<00:00, 60.41s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "for f in tqdm.tqdm(test_fs[0:10]):\n",
    "    midi = [json.load(open(f))['ids'][0]]\n",
    "    name = os.path.basename(f)\n",
    "    name = name[:-5]\n",
    "    tokens = ([x for x in midi[0]])\n",
    "    batch = [tokens]*batch_size\n",
    "    tokens = torch.LongTensor(batch).cuda()\n",
    "    with autocast():\n",
    "        sample = model.module.generate(tokens, 512, temperature=1, return_prime=False, verbose=False)\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        out = sample[i].tolist()\n",
    "        out = [x for x in out if x != 2001]\n",
    "        out_midi = tokenizer.tokens_to_midi([out])\n",
    "        out_midi.dump(f'generated_bpe/gen_{name}_{i}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250fc07-51a6-4854-80cc-7617dd288f25",
   "metadata": {},
   "source": [
    "## Zip all generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "764dde8a-f256-461b-9ed5-48ecace970ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "def zip_folder(folder_path, zip_path):\n",
    "    with ZipFile(zip_path, 'w') as zip_file:\n",
    "        for foldername, subfolders, filenames in os.walk(folder_path):\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(foldername, filename)\n",
    "                arcname = os.path.relpath(file_path, folder_path)\n",
    "                zip_file.write(file_path, arcname)\n",
    "\n",
    "# Example usage:\n",
    "folder_to_zip = 'generated'\n",
    "zip_file_path = 'gens.zip'\n",
    "\n",
    "zip_folder(folder_to_zip, zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9edbf181-e9af-4142-8479-c9d565a390ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def zip_random_files(folder_path, zip_path, sample_size):\n",
    "    all_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)]\n",
    "    \n",
    "    # Ensure the sample size is not greater than the number of files in the folder\n",
    "    sample_size = min(sample_size, len(all_files))\n",
    "\n",
    "    # Randomly select files for the sample\n",
    "    selected_files = random.sample(all_files, sample_size)\n",
    "\n",
    "    with ZipFile(zip_path, 'w') as zip_file:\n",
    "        for file_path in selected_files:\n",
    "            arcname = os.path.relpath(file_path, folder_path)\n",
    "            zip_file.write(file_path, arcname)\n",
    "\n",
    "# Example usage:\n",
    "folder_to_sample = 'norm_midi'\n",
    "zip_file_path = 'midi_sample.zip'\n",
    "sample_size = 100  # Adjust this to the desired sample size\n",
    "\n",
    "zip_random_files(folder_to_sample, zip_file_path, sample_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
